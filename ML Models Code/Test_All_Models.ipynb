{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_6dMUs3tEh4",
        "outputId": "9d1396da-1931-4b72-a9d8-02f8f01f78b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.8.2\n",
            "Hub version: 0.12.0\n",
            "GPU is NOT AVAILABLE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl0GbQMgtEqe",
        "outputId": "7f528bda-d64d-4d79-b408-83d355650666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "filename = \"/content/drive/MyDrive/dataset.zip\"\n",
        "with zipfile.ZipFile(filename, 'r') as zipp:\n",
        "  zipp.extractall()\n",
        "  zipp.close()"
      ],
      "metadata": {
        "id": "NmiK0b5ntEuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "path=\"/content/Augumented/test\"\n",
        "path=pathlib.Path(path)"
      ],
      "metadata": {
        "id": "JbNX21MJtExn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_images=0\n",
        "test_images_path={}\n",
        "for i in path.glob(\"*\"):\n",
        "  classname=str(i).split(\"/\")[-1]\n",
        "  test_images_path[classname]=[[]]\n",
        "  class_test_images=0\n",
        "  for j in i.glob(\"*\"):\n",
        "    total_images+=1\n",
        "    class_test_images+=1\n",
        "    test_images_path[classname][0].append(str(j))\n",
        "  test_images_path[classname].append(class_test_images)\n",
        "print(\"Total Test Images: \",total_images) \n",
        "# print(test_images_path[\"Cucumber\"][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMdVecIguCfj",
        "outputId": "9a59a16d-6ac7-414d-8252-b111d1f20708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Test Images:  18383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import Series,DataFrame\n",
        "classname=list(test_images_path.keys())\n",
        "values_associated=[]\n",
        "for i in classname:\n",
        "  values_associated.append(test_images_path[i][1])\n",
        "df=DataFrame(columns=[\"Class\",\"No of Test Images\"])\n",
        "df[\"Class\"]=Series(classname)\n",
        "df[\"No of Test Images\"]=Series(values_associated)\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SSXz18o9xeBt",
        "outputId": "82548bdd-1c6d-4b21-e9f7-9b03a169fc60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Class  No of Test Images\n",
              "0        Baby Potato                192\n",
              "1      Orange Carrot                501\n",
              "2             Orange                501\n",
              "3             Banana                197\n",
              "4   Kiran Watermelon                424\n",
              "5              Mango                501\n",
              "6        Green Apple                248\n",
              "7          Mango Raw                305\n",
              "8             Tomato                501\n",
              "9        Ooty Carrot                172\n",
              "10      Green Chilli                194\n",
              "11       CauliFlower                501\n",
              "12         JackFruit                501\n",
              "13            Ginger                217\n",
              "14     Green Zuchini                475\n",
              "15             Guava                252\n",
              "16              Okra                333\n",
              "17       Bittergourd                501\n",
              "18           Cabbage                501\n",
              "19    Yellow Zuchini                379\n",
              "20         Drumstick                246\n",
              "21    Yellaki Banana                501\n",
              "22       Ridge gourd                172\n",
              "23            Potato                501\n",
              "24       Broad Beans                501\n",
              "25     Green Pumpkin                501\n",
              "26              Kiwi                222\n",
              "27         Pineapple                268\n",
              "28     Brown Coconut                118\n",
              "29            Garlic                231\n",
              "30             Onion                491\n",
              "31     Custard apple                501\n",
              "32          Beetroot                501\n",
              "33       Dragonfruit                500\n",
              "34      Sweet Potato                326\n",
              "35            Radish                142\n",
              "36    Green Capscium                304\n",
              "37             Lemon                474\n",
              "38     Black brinjal                352\n",
              "39        Strawberry                501\n",
              "40     Pointed gourd                233\n",
              "41            Papaya                501\n",
              "42              Pear                501\n",
              "43      Green Grapes                369\n",
              "44               Yam                186\n",
              "45         Red Apple                501\n",
              "46      Red Capscium                253\n",
              "47      French Beans                427\n",
              "48        Sweet lime                206\n",
              "49   Yellow Capscium                208\n",
              "50         Muskmelon                249"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-758b3cb2-b260-42a8-be7e-a6778eb1067d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>No of Test Images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baby Potato</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Orange Carrot</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Orange</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Banana</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kiran Watermelon</td>\n",
              "      <td>424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Mango</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Green Apple</td>\n",
              "      <td>248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Mango Raw</td>\n",
              "      <td>305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Tomato</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Ooty Carrot</td>\n",
              "      <td>172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Green Chilli</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CauliFlower</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>JackFruit</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Ginger</td>\n",
              "      <td>217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Green Zuchini</td>\n",
              "      <td>475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Guava</td>\n",
              "      <td>252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Okra</td>\n",
              "      <td>333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Bittergourd</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Cabbage</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Yellow Zuchini</td>\n",
              "      <td>379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Drumstick</td>\n",
              "      <td>246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Yellaki Banana</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Ridge gourd</td>\n",
              "      <td>172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Potato</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Broad Beans</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Green Pumpkin</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Kiwi</td>\n",
              "      <td>222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Pineapple</td>\n",
              "      <td>268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Brown Coconut</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Garlic</td>\n",
              "      <td>231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Onion</td>\n",
              "      <td>491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Custard apple</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Beetroot</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Dragonfruit</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Sweet Potato</td>\n",
              "      <td>326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Radish</td>\n",
              "      <td>142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Green Capscium</td>\n",
              "      <td>304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Lemon</td>\n",
              "      <td>474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Black brinjal</td>\n",
              "      <td>352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Strawberry</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Pointed gourd</td>\n",
              "      <td>233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Papaya</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Pear</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Green Grapes</td>\n",
              "      <td>369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Yam</td>\n",
              "      <td>186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Red Apple</td>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Red Capscium</td>\n",
              "      <td>253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>French Beans</td>\n",
              "      <td>427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Sweet lime</td>\n",
              "      <td>206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Yellow Capscium</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Muskmelon</td>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-758b3cb2-b260-42a8-be7e-a6778eb1067d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-758b3cb2-b260-42a8-be7e-a6778eb1067d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-758b3cb2-b260-42a8-be7e-a6778eb1067d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.histogram(df,x=\"Class\",y=\"No of Test Images\",title=\"Test Images Per Class\")\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "XH6qn1G7xeL0",
        "outputId": "582c48b2-71e2-40c2-932d-fc2fd7e48ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"020e14d7-106d-4d70-ac21-b4e70801c168\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"020e14d7-106d-4d70-ac21-b4e70801c168\")) {                    Plotly.newPlot(                        \"020e14d7-106d-4d70-ac21-b4e70801c168\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"histfunc\":\"sum\",\"hovertemplate\":\"Class=%{x}<br>sum of No of Test Images=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[\"Baby Potato\",\"Orange Carrot\",\"Orange\",\"Banana\",\"Kiran Watermelon\",\"Mango\",\"Green Apple\",\"Mango Raw\",\"Tomato\",\"Ooty Carrot\",\"Green Chilli\",\"CauliFlower\",\"JackFruit\",\"Ginger\",\"Green Zuchini\",\"Guava\",\"Okra\",\"Bittergourd\",\"Cabbage\",\"Yellow Zuchini\",\"Drumstick\",\"Yellaki Banana\",\"Ridge gourd\",\"Potato\",\"Broad Beans\",\"Green Pumpkin\",\"Kiwi\",\"Pineapple\",\"Brown Coconut\",\"Garlic\",\"Onion\",\"Custard apple\",\"Beetroot\",\"Dragonfruit\",\"Sweet Potato\",\"Radish\",\"Green Capscium\",\"Lemon\",\"Black brinjal\",\"Strawberry\",\"Pointed gourd\",\"Papaya\",\"Pear\",\"Green Grapes\",\"Yam\",\"Red Apple\",\"Red Capscium\",\"French Beans\",\"Sweet lime\",\"Yellow Capscium\",\"Muskmelon\"],\"xaxis\":\"x\",\"y\":[192,501,501,197,424,501,248,305,501,172,194,501,501,217,475,252,333,501,501,379,246,501,172,501,501,501,222,268,118,231,491,501,501,500,326,142,304,474,352,501,233,501,501,369,186,501,253,427,206,208,249],\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Class\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"sum of No of Test Images\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Test Images Per Class\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('020e14d7-106d-4d70-ac21-b4e70801c168');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes=(\"Baby Potato\", \"Banana\", \"Beetroot\", \"Bittergourd\", \"Black brinjal\", \"Broad Beans\", \"Brown Coconut\", \"Cabbage\", \"CauliFlower\", \"Custard apple\", \"Dragonfruit\", \"Drumstick\", \"French Beans\", \"Garlic\",\"Ginger\",\"Green Apple\", \"Green Capscium\", \"Green Chilli\", \"Green Grapes\", \"Green Pumpkin\", \"Green Zuchini\", \"Guava\", \"JackFruit\", \"Kiran Watermelon\", \"Kiwi\", \"Lemon\", \"Mango\", \"Mango Raw\",\"Muskmelon\", \"Okra\", \"Onion\", \"Ooty Carrot\", \"Orange\", \"Orange Carrot\", \"Papaya\", \"Pear\", \"Pineapple\", \"Pointed gourd\", \"Potato\", \"Radish\", \"Red Apple\", \"Red Capscium\", \"Ridge gourd\", \"Strawberry\",\"Sweet Potato\", \"Sweet lime\", \"Tomato\", \"Yam\", \"Yellaki Banana\", \"Yellow Capscium\", \"Yellow Zuchini\")"
      ],
      "metadata": {
        "id": "5Ttsxv3Pxegs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter1 = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/Tflite_Models/EfficentNetv2_NonAugumented.tflite\")\n",
        "# This little helper wraps the TFLite Interpreter as a numpy-to-numpy function.\n",
        "def lite_model_1(images):\n",
        "  interpreter1.allocate_tensors()\n",
        "  interpreter1.set_tensor(interpreter1.get_input_details()[0]['index'], images)\n",
        "  interpreter1.invoke()\n",
        "  return interpreter1.get_tensor(interpreter1.get_output_details()[0]['index'])"
      ],
      "metadata": {
        "id": "kJxi0DH42Ffb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQpmtF6rs7Oq"
      },
      "outputs": [],
      "source": [
        "interpreter2 = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/Tflite_Models/Mobilenet_Non_Augumented.tflite\")\n",
        "# This little helper wraps the TFLite Interpreter as a numpy-to-numpy function.\n",
        "def lite_model_2(images):\n",
        "  interpreter2.allocate_tensors()\n",
        "  interpreter2.set_tensor(interpreter2.get_input_details()[0]['index'], images)\n",
        "  interpreter2.invoke()\n",
        "  return interpreter2.get_tensor(interpreter2.get_output_details()[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter3 = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/Tflite_Models/Nasnet_Non_Augumented.tflite\")\n",
        "# This little helper wraps the TFLite Interpreter as a numpy-to-numpy function.\n",
        "def lite_model_3(images):\n",
        "  # print(got)\n",
        "  interpreter3.allocate_tensors()\n",
        "  interpreter3.set_tensor(interpreter3.get_input_details()[0]['index'], images)\n",
        "  interpreter3.invoke()\n",
        "  return interpreter3.get_tensor(interpreter3.get_output_details()[0]['index'])"
      ],
      "metadata": {
        "id": "F1052iff9Zgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter4 = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/Tflite_Models/Mobilenet_Augumented.tflite\")\n",
        "# This little helper wraps the TFLite Interpreter as a numpy-to-numpy function.\n",
        "def lite_model_4(images):\n",
        "  interpreter4.allocate_tensors()\n",
        "  interpreter4.set_tensor(interpreter4.get_input_details()[0]['index'], images)\n",
        "  interpreter4.invoke()\n",
        "  return interpreter4.get_tensor(interpreter4.get_output_details()[0]['index'])"
      ],
      "metadata": {
        "id": "R34bSR43-bpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter5 = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/Tflite_Models/EfficentNetv2_Augumented.tflite\")\n",
        "# This little helper wraps the TFLite Interpreter as a numpy-to-numpy function.\n",
        "def lite_model_5(images):\n",
        "  # print(got)\n",
        "  interpreter5.allocate_tensors()\n",
        "  interpreter5.set_tensor(interpreter5.get_input_details()[0]['index'], images)\n",
        "  interpreter5.invoke()\n",
        "  return interpreter5.get_tensor(interpreter5.get_output_details()[0]['index'])"
      ],
      "metadata": {
        "id": "JOP_WDtdRxK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interpreter6 = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/tflite_models/nasnet_mobile_AUG_San_98.tflite\")\n",
        "# # This little helper wraps the TFLite Interpreter as a numpy-to-numpy function.\n",
        "# def lite_model_6(images):\n",
        "#   # print(got)\n",
        "#   interpreter6.allocate_tensors()\n",
        "#   interpreter6.set_tensor(interpreter6.get_input_details()[0]['index'], images)\n",
        "#   interpreter6.invoke()\n",
        "#   return interpreter6.get_tensor(interpreter6.get_output_details()[0]['index'])"
      ],
      "metadata": {
        "id": "Yu9XSzLYGloK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------EFFICENTNETV2 NON AUGMENTATION (1ST)-----------------------------\n",
        "correctclass=0\n",
        "for i in test_images_path:\n",
        "  for j in test_images_path[i][0]:\n",
        "    try:\n",
        "      img = tf.io.read_file(j)\n",
        "      tensor = tf.io.decode_image(img, channels=3, dtype=tf.dtypes.float32)\n",
        "      tensor = tf.image.resize(tensor, [224, 224])\n",
        "      input_tensor = tf.expand_dims(tensor, axis=0)\n",
        "      prediction=classes[np.argmax(lite_model_1(input_tensor)[0])]\n",
        "      if(prediction==i):\n",
        "        correctclass+=1\n",
        "    except:\n",
        "      print(j,\"Causes Error\")\n",
        "      pass\n",
        "print(\"EfficientNetV2(Non Augmented) Number of Correct Predictions is \",correctclass,\" out of \",total_images)\n",
        "print(\"EfficientNetV2(Non Augmented) Accuracy of testing is \",correctclass/total_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG1mr1ULv5tN",
        "outputId": "b987dde9-349e-4d53-e59d-3f91c14c8a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EfficientNetV2(Non Augmented) Number of Correct Predictions is  14427  out of  18383\n",
            "EfficientNetV2(Non Augmented) Accuracy of testing is  0.78480117499864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------MOBILENETV2 AUGMENTATION(2ND)---------------------\n",
        "correctclass=0\n",
        "for i in test_images_path:\n",
        "  for j in test_images_path[i][0]:\n",
        "    try:\n",
        "      img = tf.io.read_file(j)\n",
        "      tensor = tf.io.decode_image(img, channels=3, dtype=tf.dtypes.float32)\n",
        "      tensor = tf.image.resize(tensor, [224, 224])\n",
        "      input_tensor = tf.expand_dims(tensor, axis=0)\n",
        "      prediction=classes[np.argmax(lite_model_2(input_tensor)[0])]\n",
        "      if(prediction==i):\n",
        "        correctclass+=1\n",
        "    except:\n",
        "      print(j,\"Causes Error\")\n",
        "      pass\n",
        "print(\"MobileNetV2(Non Augmented) Number of Correct Predictions is \",correctclass,\" out of \",total_images)\n",
        "print(\"MobileNetV2(Non Augmented) Accuracy of testing is \",correctclass/total_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79u_IsMv6NJE",
        "outputId": "5cf93079-421b-4136-c030-02873422d1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNetV2(Non Augmented) Number of Correct Predictions is  15326  out of  18383\n",
            "MobileNetV2(Non Augmented) Accuracy of testing is  0.8337050535821139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------------------------NASNET WITHOUT AUGMENTATION(5TH)------------------\n",
        "correctclass=0\n",
        "for i in test_images_path:\n",
        "  for j in test_images_path[i][0]:\n",
        "    try:\n",
        "      img = tf.io.read_file(j)\n",
        "      # print(img)\n",
        "      tensor = tf.io.decode_image(img, channels=3, dtype=tf.dtypes.float32)\n",
        "      tensor = tf.image.resize(tensor, [224, 224])\n",
        "      input_tensor = tf.expand_dims(tensor, axis=0)\n",
        "      prediction=classes[np.argmax(lite_model_3(input_tensor)[0])]\n",
        "      # print(\"prediction is\",prediction,\"class is\",i )\n",
        "      if(prediction==i):\n",
        "        correctclass+=1\n",
        "    except:\n",
        "      # print(j,\"Causes Error\")\n",
        "      pass\n",
        "print(\"NasNetV2(Non Augmented) Number of Correct Predictions is \",correctclass,\" out of \",total_images)\n",
        "print(\"NasNetV2(Non Augmented) Accuracy of testing is \",correctclass/total_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcqivdCC-m7O",
        "outputId": "ec053af9-ab2e-40bf-f7a9-9b583c8ebcd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NasNetV2(Non Augmented) Number of Correct Predictions is  13071  out of  18383\n",
            "NasNetV2(Non Augmented) Accuracy of testing is  0.7110373714845237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------MOBILENET AUGMENTATION(6TH)------------------------------\n",
        "correctclass=0\n",
        "for i in test_images_path:\n",
        "  for j in test_images_path[i][0]:\n",
        "    try:\n",
        "      img = tf.io.read_file(j)\n",
        "      # print(img)\n",
        "      tensor = tf.io.decode_image(img, channels=3, dtype=tf.dtypes.float32)\n",
        "      tensor = tf.image.resize(tensor, [224, 224])\n",
        "      input_tensor = tf.expand_dims(tensor, axis=0)\n",
        "      prediction=classes[np.argmax(lite_model_4(input_tensor)[0])]\n",
        "      # print(\"prediction is\",prediction,\"class is\",i )\n",
        "      if(prediction==i):\n",
        "        correctclass+=1\n",
        "    except:\n",
        "      # print(j,\"Causes Error\")\n",
        "      pass\n",
        "print(\"MobileNetV2(Augmented) Number of Correct Predictions is \",correctclass,\" out of \",total_images)\n",
        "print(\"MobileNetV2(Augmented) Accuracy of testing is \",correctclass/total_images)"
      ],
      "metadata": {
        "id": "EnxziRP1_MRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1617875f-3e19-4f61-c7f6-de6b6c981872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNetV2(Augmented) Number of Correct Predictions is  17747  out of  18383\n",
            "MobileNetV2(Augmented) Accuracy of testing is  0.9654028178208127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------------EFFICIENTNETV2 AUGMENTATION(4TH)-------------------------\n",
        "correctclass=0\n",
        "for i in test_images_path:\n",
        "  for j in test_images_path[i][0]:\n",
        "    try:\n",
        "      img = tf.io.read_file(j)\n",
        "      tensor = tf.io.decode_image(img, channels=3, dtype=tf.dtypes.float32)\n",
        "      tensor = tf.image.resize(tensor, [224, 224])\n",
        "      input_tensor = tf.expand_dims(tensor, axis=0)\n",
        "      prediction=classes[np.argmax(lite_model_5(input_tensor)[0])]\n",
        "      if(prediction==i):\n",
        "        correctclass+=1\n",
        "    except:\n",
        "      # print(j,\"Causes Error\")\n",
        "      pass\n",
        "print(\"EfficientNet(Augmented) Number of Correct Predictions is \",correctclass,\" out of \",total_images)\n",
        "print(\"EfficientNet(Augmented) Accuracy of testing is \",correctclass/total_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VgIPMgN-7fB",
        "outputId": "99a9f0b9-1e36-4a9f-b93e-df7d72346798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EfficientNet(Augmented) Number of Correct Predictions is  17727  out of  18383\n",
            "EfficientNet(Augmented) Accuracy of testing is  0.9643148561170647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #------------------------NASNET WITH AUGMENTATION(3RD)----------------------------------\n",
        "# correctclass=0\n",
        "# for i in test_images_path:\n",
        "#   for j in test_images_path[i][0]:\n",
        "#     try:\n",
        "#       img = tf.io.read_file(j)\n",
        "#       tensor = tf.io.decode_image(img, channels=3, dtype=tf.dtypes.float32)\n",
        "#       tensor = tf.image.resize(tensor, [224, 224])\n",
        "#       input_tensor = tf.expand_dims(tensor, axis=0)\n",
        "#       prediction=classes[np.argmax(lite_model_6(input_tensor)[0])]\n",
        "#       if(prediction==i):\n",
        "#         correctclass+=1\n",
        "#     except:\n",
        "#       # print(j,\"Causes Error\")\n",
        "#       pass\n",
        "# print(\"NasNet(augmented) Number of Correct Predictions is \",correctclass,\" out of \",total_images)\n",
        "# print(\"NasNet(augmented) Accuracy of testing is \",correctclass/total_images)"
      ],
      "metadata": {
        "id": "SUNOG-N7SXAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------ENSEMBLE MODEL---------------------------------------------------\n",
        "correctclass=0\n",
        "for i in test_images_path:\n",
        "  for j in test_images_path[i][0]:\n",
        "    try:\n",
        "        img = tf.io.read_file(j)\n",
        "        tensor = tf.io.decode_image(img, channels=3, dtype=tf.dtypes.float32)\n",
        "        tensor = tf.image.resize(tensor, [224, 224])\n",
        "        input_tensor = tf.expand_dims(tensor, axis=0)\n",
        "        #print(lite_model_6(input_tensor)[0])\n",
        "        # prediction=classes[np.argmax(lite_model_6(input_tensor)[0])]\n",
        "\n",
        "        b1 = lite_model_2(input_tensor)[0]\n",
        "        b2 = lite_model_4(input_tensor)[0]\n",
        "        b3 = lite_model_5(input_tensor)[0]\n",
        "        # prediction_1 = classes[np.argmax(b1)]\n",
        "        # prediction_2 = classes[np.argmax(b2)]\n",
        "        # prediction_3 = classes[np.argmax(b3)]\n",
        "        # print(b3)\n",
        "        b1 = 2.*(b1 - np.min(b1))/np.ptp(b1)-1\n",
        "        b2 = 2.*(b2 - np.min(b2))/np.ptp(b2)-1\n",
        "        b3 = 2.*(b3 - np.min(b3))/np.ptp(b3)-1\n",
        "        b = 0.30*b1+0.35*b2+0.35*b3\n",
        "        prediction = classes[np.argmax(b)]\n",
        "        if(prediction==i):\n",
        "                correctclass+=1\n",
        "        # print(prediction_1,prediction_2,prediction_3,prediction_4)\n",
        "    except:\n",
        "      # print(j,\"Causes Error\")\n",
        "      pass\n",
        "print(\"Number of Correct Predictions is \",correctclass,\" out of \",total_images)\n",
        "print(\"Accuracy of testing is \",correctclass/total_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJv-hIgY_zoL",
        "outputId": "974ba2fa-6bbc-4468-dcf7-1cd7304327f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Correct Predictions is  15990  out of  18383\n",
            "Accuracy of testing is  0.8698253821465485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nasnet-> 98% ->0.98 ==> weight_to_nasnet  => 0.33 =>[-20,-19,-18]\n",
        "# Mobilenet -> 99.5% ->0.995  ==>weight_to_mobilenet=>0.34 [-10,9]\n",
        "# EfficientNet-> 97% ->0.97  =>weight_to_effiecint=>0.32 [-7]"
      ],
      "metadata": {
        "id": "jCcs0ddcMWey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------ENSEMBLE MODEL---------------------------------------------------\n",
        "correctclass=0\n",
        "for i in test_images_path:\n",
        "  for j in test_images_path[i][0]:\n",
        "    try:\n",
        "        img = tf.io.read_file(j)\n",
        "        tensor = tf.io.decode_image(img, channels=3, dtype=tf.dtypes.float32)\n",
        "        tensor = tf.image.resize(tensor, [224, 224])\n",
        "        input_tensor = tf.expand_dims(tensor, axis=0)\n",
        "        #print(lite_model_6(input_tensor)[0])\n",
        "        # prediction=classes[np.argmax(lite_model_6(input_tensor)[0])]\n",
        "\n",
        "        # b1 = lite_model_2(input_tensor)[0]\n",
        "        b2 = lite_model_4(input_tensor)[0]\n",
        "        b3 = lite_model_5(input_tensor)[0]\n",
        "        # prediction_1 = classes[np.argmax(b1)]\n",
        "        # prediction_2 = classes[np.argmax(b2)]\n",
        "        # prediction_3 = classes[np.argmax(b3)]\n",
        "        # print(b3)\n",
        "        # b1 = 2.*(b1 - np.min(b1))/np.ptp(b1)-1\n",
        "        b2 = 2.*(b2 - np.min(b2))/np.ptp(b2)-1\n",
        "        b3 = 2.*(b3 - np.min(b3))/np.ptp(b3)-1\n",
        "        b = 0.50*b2+0.50*b3\n",
        "        prediction = classes[np.argmax(b)]\n",
        "        if(prediction==i):\n",
        "                correctclass+=1\n",
        "        # print(prediction_1,prediction_2,prediction_3,prediction_4)\n",
        "    except:\n",
        "      # print(j,\"Causes Error\")\n",
        "      pass\n",
        "print(\"Number of Correct Predictions is \",correctclass,\" out of \",total_images)\n",
        "print(\"Accuracy of testing is \",correctclass/total_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnfrfForF4Q9",
        "outputId": "11975d44-4525-4088-e6be-a9f16f3f74e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Correct Predictions is  17956  out of  18383\n",
            "Accuracy of testing is  0.9767720176249796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z5p1HWZ9GBHR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}